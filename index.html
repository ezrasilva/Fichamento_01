<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Fichamento | LABit</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css" />
  <script src="https://unpkg.com/lucide@latest"></script>
</head>
<body>
  <header>
    <div class="navbar" id="navbar">
      <div class="logo">
        <img src="logo.png" alt="Logo LABit">

      </div>
      <div class="menu-toggle" onclick="toggleMenu()">
        <span></span>
        <span></span>
        <span></span>
      </div>
      <nav>
        <ul>
          <li><a href="#"><i data-lucide="home"></i> INICIO</a></li>
          <li><a href="#"><i data-lucide="search"></i> PESQUISAS</a></li>
          <li><a href="#"><i data-lucide="mail"></i> CONTATO</a></li>
          <li><a href="#"><i data-lucide="file-text"></i> ARTIGOS</a></li>
          <li><a href="#"><i data-lucide="users"></i> SOBRE NÓS</a></li>
        </ul>
      </nav>
    </div>
  </header>

  <main>
    <div class="content-container">
      <span class="breadcrumbs">
        <a href="#">Artigos</a> / <a href="#">Fichamentos</a> / <a href="#">LLMs</a>
      </span>

      <h1>Large Language Models (LLMs): survey, technical frameworks, and future challenges</h1>
      <p class="info">Autor: <strong>Pranjal Kumar</strong> &nbsp;|&nbsp; Ano: <em>2024</em> &nbsp;|&nbsp; Revista: <em>Artificial Intelligence Review</em></p>

      <div class="article-intro">
        <p>O artigo intitulado <em>"Large Language Models (LLMs): survey, technical frameworks, and future challenges"</em>, elaborado pelo pesquisador Pranjal Kumar e publicado na revista <em>Artificial Intelligence Review</em> em agosto de 2024 oferece uma visão completa sobre os modelos de linguagem de grande escala (LLMs). O objetivo central é apresentar uma análise técnica e crítica das evoluções, utilizações e dificuldades inerentes ao progresso desses modelos, que hoje formam a base de muitos sistemas de inteligência artificial.</p>
      </div>

      <div class="section">
        <h2>Abordagem Técnica e Fundamentos</h2>
        <p>O estudo ressalta desde o início que os LLMs representam uma mudança fundamental na maneira como as máquinas lidam com a linguagem humana. Kumar organiza sua abordagem de forma clara, usando uma comparação com construções em camadas para descrever a estrutura técnica dos modelos. Isso inclui a explicação de mecanismos internos, como autoatenção, embeddings posicionais e a arquitetura Transformer, que transformou a área do processamento de linguagem natural (PLN). Ele também examina as fases de aprendizado desses modelos, como o pré-treinamento e o ajuste fino, cruciais para a adaptação dos LLMs a tarefas específicas.</p>
      </div>

      <div class="section">
        <h2>Aplicações e Desafios</h2>
        <p>Além da base técnica, o estudo explora em profundidade as aplicações práticas desses modelos em vários setores, como biomedicina, educação, pesquisa científica, auxílio jurídico, criação de código e até em sistemas multimodais que combinam texto e imagem. Apesar dos avanços notáveis, o autor adverte sobre desafios sérios que acompanham essa evolução, como a interpretabilidade dos modelos, a existência de preconceitos algorítmicos, as preocupações com a privacidade dos dados e o alto custo computacional, um dos fatores mais críticos ao pensar em sustentabilidade e escalabilidade.</p>
        
        <div class="figure-container">
          <img src="fig1.png" alt="Taxonomia dos componentes técnicos de LLMs" class="figure-image" />
          <p class="figure-caption">Figura 1 – Taxonomia do artigo</p>
        </div>
      </div>

      <div class="section">
        <h2>Tecnologias e Métricas de Avaliação</h2>
        <p>Kumar inicia sua análise comparativa destacando alguns dos grandes nomes dos modelos de linguagem de larga escala (LLMs), como GPT‑3, GPT‑4, PaLM, Megatron‑Turing NLG, Jurassic‑1 Jumbo e LLaMA. Em vez de apenas listar essas soluções, ele investiga como cada uma se posiciona dentro dos paradigmas de modelos autoregressivos (que predizem o próximo token) versus modelos pré‑treinados (que aprendem representações gerais antes de serem ajustados para tarefas específicas), além de discutir como cada arquitetura se comporta em contextos multimodais, isto é, quando texto e imagem são processados de forma conjunta em configurações fusion‑encoder ou dual‑encoder.</p>

        <p>Quando o autor menciona “frameworks técnicos”, ele não está comparando diretamente bibliotecas de software como PyTorch, TensorFlow ou HuggingFace Transformers. Na verdade, Kumar usa esse termo para se referir às diferentes estratégias de pesquisa — por exemplo, as abordagens de pré‑treino e fine‑tuning, as variações de atenção cruzada entre modalidades e os esquemas de injeção de prompts ou de adaptação de baixo custo (LoRA). As implementações em PyTorch ou TensorFlow aparecem apenas como referências de implementação, sem que haja uma seção dedicada a comparar desempenho ou facilidades de uso dessas ferramentas.</p>

        <p>No que diz respeito às técnicas de embeddings para representar palavras e frases em vetores num espaço contínuo, Kumar faz um passeio desde os métodos clássicos, como análise semântica latente (LSA), Word2Vec, GloVe e FastText, até abordagens mais modernas baseadas em contextualização dinâmica, como CoVe e outras variantes que utilizam redes recorrentes ou camadas Transformer. Para cada técnica, ele descreve como as diferenças de arquitetura e de objetivo de treinamento impactam a fidelidade semântica e a capacidade de capturar nuances de significado.</p>

        <p>Por fim, o survey dedica uma seção às métricas de avaliação, alinhando cada tarefa a indicadores apropriados. Em sistemas de perguntas e respostas (QA), ele destaca a importância de medir precisão, recall e F1‑score em benchmarks padronizados, enquanto em tarefas de classificação de texto e reconhecimento de entidades (NER) o F1‑score costuma ser o principal critério de sucesso, complementado por acurácia geral. Na geração de texto, recomenda-se usar perplexidade para avaliar a fluência do modelo e BLEU para aferir a adequação ao texto de referência. Já em cenários multimodais, como visual question answering ou recuperação de imagens por texto, são mais comuns métricas de acurácia em Visual Question Answering (VQA) e recall@K para ranking de elementos multimodais; o artigo não aborda, porém, métricas de segmentação de imagem como o IOU.</p>
      </div>

      <div class="section">
        <h2>Comparações Técnicas</h2>
        <p>Duas tabelas mostram mais detalhes. A Tabela 1 resume os modelos principais, com o ano de lançamento, número de parâmetros, arquitetura e dados usados no treinamento. A Tabela 2 compara técnicas de embeddings, dividindo-as por tipo (contagem, previsão ou contexto) e mostrando seus pontos fortes e fracos.</p>
        
        <div class="tables-container">
          <div class="table-wrapper">
            <h3>Tabela 1 – Visão Geral de Modelos LLMs</h3>
            <table class="styled-table">
              <thead>
                <tr>
                  <th>Modelo</th>
                  <th>Ano</th>
                  <th>Parâmetros</th>
                  <th>Arquitetura</th>
                  <th>Dataset (GB/TB)</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>GPT-3</td>
                  <td>2020</td>
                  <td>175B</td>
                  <td>Decoder</td>
                  <td>570GB</td>
                </tr>
                <tr>
                  <td>BERT</td>
                  <td>2018</td>
                  <td>110M</td>
                  <td>Encoder</td>
                  <td>3.3TB</td>
                </tr>
                <tr>
                  <td>PaLM</td>
                  <td>2022</td>
                  <td>540B</td>
                  <td>Decoder</td>
                  <td>n/a</td>
                </tr>
                <tr>
                  <td>Gopher</td>
                  <td>2021</td>
                  <td>280B</td>
                  <td>Decoder</td>
                  <td>10.5TB</td>
                </tr>
              </tbody>
              <caption>Tabela construída com base na Tabela 6 do artigo de Kumar (2024), p. 20</caption>
            </table>
          </div>

          <div class="table-wrapper">
            <h3>Tabela 2 – Comparativo de Embeddings</h3>
            <table class="styled-table">
              <thead>
                <tr>
                  <th>Método</th>
                  <th>Tipo</th>
                  <th>Vantagem</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Word2Vec</td>
                  <td>Previsão</td>
                  <td>Captura semântica com janelas de contexto</td>
                </tr>
                <tr>
                  <td>GloVe</td>
                  <td>Contagem</td>
                  <td>Baseado em coocorrência global</td>
                </tr>
                <tr>
                  <td>FastText</td>
                  <td>Sub-palavra</td>
                  <td>Trabalha bem com palavras raras e desconhecidas</td>
                </tr>
                <tr>
                  <td>CoVe</td>
                  <td>Contextual</td>
                  <td>Captura o contexto dinâmico das sentenças</td>
                </tr>
              </tbody>
              <caption>Tabela construída com base na Seção 5 do artigo de Kumar (2024)</caption>
            </table>
          </div>
        </div>
      </div>

      <div class="section">
        <h2>Conclusões e Impacto</h2>
        <p>Na parte final, Kumar volta a falar sobre algo importante: os LLMs melhoram muito o desempenho, como as Leis de Escala de Kaplan et al. (2020) já diziam, mas gastam muita energia e prejudicam o meio ambiente. Ele propõe usar métodos mais sustentáveis, como distilação, sparsity, quantização e energia renovável para treinar os modelos.</p>
        
        <p>O artigo termina avisando sobre a importância de regras e ética nos LLMs. Kumar cita o relatório Stanford AI Index 2024, que se preocupa com o meio ambiente e com os preconceitos em sistemas de IA generativa. Ele insiste que é preciso ter transparência, responsabilidade social e ética no desenvolvimento dessas tecnologias, ainda mais porque elas são usadas no mundo todo.</p>
      </div>
    </div>
  </main>

  <footer>
    <div class="footer-content">
      <p>© 2024 LABit. Todos os direitos reservados.</p>
    </div>
  </footer>

  <script>
    function toggleMenu() {
      document.getElementById('navbar').classList.toggle('active');
    }
    lucide.createIcons();
  </script>
</body>
</html>